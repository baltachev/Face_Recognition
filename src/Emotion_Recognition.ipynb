{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "dataset_path = '/Users/baltachev/Documents/fer2013/fer2013/fer2013.csv'\n",
    "image_size=(48,48)\n",
    " \n",
    "def load_fer2013():\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "    return faces, emotions\n",
    " \n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    " \n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установим параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 128\n",
    "num_epochs = 15\n",
    "input_shape = (48, 48, 1)\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 5\n",
    "base_path = '/Users/baltachev/Documents/face_recognition/models/'\n",
    "optimizer = Adam(lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составим архитектуру сети\n",
    "#### Используем основу VGG - сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "model = Sequential()\n",
    "\n",
    "#Block 1\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = \"he_normal\", padding=\"same\", input_shape = input_shape))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = \"he_normal\", padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "#Block 2\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = \"he_normal\", padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer = \"he_normal\", padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "# Block 3\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer = \"he_normal\", padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer = \"he_normal\", padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "# Block 4    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block 5\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Block 6 \n",
    "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настроим callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "log_file_path = base_path + '_emotion_training_vgg.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_vgg'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скомпилируем и обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain, batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После 15 эпох accuracy на валидационных данных составило 0.6101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим как работает сеть на тестовых изображениях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](happy_mar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](sad_mar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](surprised_mar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](angry_mar.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
